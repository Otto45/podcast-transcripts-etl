import os
from typing import List

from assemblyai import Transcript

from customtypes.podcast_episode import PodcastEpisode, PodcastEpisodeTimestamp

def timestamp_to_ms(timestamp) -> int:
    hours, minutes, seconds = map(int, timestamp.split(':'))
    return (hours * 3600 + minutes * 60 + seconds) * 1000

def extract_episode_timestamps_and_titles(description) -> List[PodcastEpisodeTimestamp]:
    import re

    lines = description.split('\n')
    
    # Regular expression to match (HH:MM:SS) Title format
    pattern = r'^\((\d{2}:\d{2}:\d{2})\)\s(.+)$'
    
    results = []
    for line in lines:
        match = re.match(pattern, line.strip())
        if match:
            timestamp, title = match.groups()
            podcast_episode_timestamp = PodcastEpisodeTimestamp(timestamp_to_ms(timestamp), title.strip())
            results.append(podcast_episode_timestamp)
    
    return results

def get_names_in_text(text: str) -> List[str]:
    import spacy

    nlp = spacy.load("en_core_web_sm")

    # Process the title to find named entities
    # TODO: Improve this to handle prefixes and suffixes (e.g. "Dr.", "Sr.", etc.)
    doc = nlp(text)

    # Extract entities labeled as 'PERSON'
    persons = set(ent.text for ent in doc.ents if ent.label_ == 'PERSON')

    # Return the unique names as a list
    return list(persons)

def generate_transcript(
        audio_url: str, num_speakers: int, auto_chapters = False
) -> Transcript:
    import assemblyai as aai

    aai.settings.api_key = os.environ["ASSEMBLY_AI_API_TOKEN"]
    
    # We are enabling speaker diarization to label the transcript text w/ the speaker
    # NOTE: You can only enable auto_chapters or summarization individually. If we need both,
    # we'll have to submit two separate requests to the API.
    config = aai.TranscriptionConfig(
        speaker_labels=True,
        speakers_expected=num_speakers,
        auto_chapters=auto_chapters
    )

    transcriber = aai.Transcriber()
    transcript = transcriber.transcribe(audio_url, config=config)
    
    return transcript

def get_generated_transcript(id: str):
    import assemblyai as aai

    aai.settings.api_key = os.environ["ASSEMBLY_AI_API_TOKEN"]
    
    transcript = aai.Transcript.get_by_id(id)

    return transcript

def match_speaker_label_with_name(speaker_label: str, podcast_guest_names: List[str]) -> str:
    # TODO: FIX THIS METHOD TO ACTUAL PICK THE RIGHT NAME FOR THE SPEAKER LABEL
    match speaker_label:
        case 'A':
            return podcast_guest_names[0]
        case 'B':
            return podcast_guest_names[1]
        case 'C':
            return podcast_guest_names[2]
        case 'D':
            return podcast_guest_names[3]
        case 'E':
            return podcast_guest_names[4]
        case _:
            raise ValueError(f'Could not match speaker label "{speaker_label}" with a name')

def create_episode_document(podcast_episode: PodcastEpisode, transcript: Transcript):
    document = {}

    document['podcast_name'] = podcast_episode.podcast_name
    document['title'] = podcast_episode.title
    document['audio_url'] = podcast_episode.audio_url
    document['description'] = podcast_episode.description
    
    if podcast_episode.original_guid is not None:
        document['original_guid'] = podcast_episode.original_guid
    
    if podcast_episode.link is not None:
        document['link'] = podcast_episode.link

    if podcast_episode.publish_date is not None:
        document['publish_date'] = podcast_episode.publish_date

    if podcast_episode.timestamps is not None:
        episode_timestamps = []

        for timestamp in podcast_episode.timestamps:
            episode_timestamp = {
                'title': timestamp.title,
                'timestamp_ms': timestamp.timestamp_ms
            }

            episode_timestamps.append(episode_timestamp)
        
        document['chapters'] = episode_timestamps

    else: # We are assuming the chapters were generated by AssemblyAI because the episode did not provide them
        episode_chapters = []

        for chapter in transcript.chapters:
            episode_chapter = {
                'title': chapter.headline,
                'timestamp_ms': chapter.start
            }

            episode_chapters.append(episode_chapter)

        document['chapters'] = episode_chapters
    
    episode_utterances = []
    podcast_guests = [podcast_episode.podcast_host]

    for name in get_names_in_text(podcast_episode.title):
        podcast_guests.append(name)

    for utterance in transcript.utterances:
        episode_utterance = {
            'speaker': match_speaker_label_with_name(utterance.speaker, podcast_guests),
            'text': utterance.text,
            'start_ms': utterance.start,
            'end_ms': utterance.end
        }

        episode_utterances.append(episode_utterance)
    
    document['transcript'] = episode_utterances
    
    return document

def save_episode_document(document):    
    from pymongo.mongo_client import MongoClient
    from pymongo.server_api import ServerApi

    uri = os.environ['MONGODB_ATLAS_CLUSTER_URI']
    client = MongoClient(uri, server_api=ServerApi('1'))

    try:
        db = client['pod_search']
        collection = db['podcast_episodes']
        collection.insert_one(document)
    except Exception as e:
        print(e)

def prep_episode_document_for_vector_embedding(document) -> tuple[List[str], List[str]]:
    from langchain.text_splitter import RecursiveCharacterTextSplitter

    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
        chunk_size=1000, chunk_overlap=150, allowed_special="all"
    )

    text_chunks: List[str] = []
    metadatas: List[str] = []

    for utterance in document['transcript']:
        utterance_metadata = {
            'speaker': utterance['speaker'],
            'start_ms': utterance['start_ms'],
            'end_ms': utterance['end_ms']
        }

        utterance_chunks = text_splitter.split_text(utterance['text'])
        metadatas_for_utterance_chunks = [utterance_metadata] * len(utterance_chunks)

        text_chunks += utterance_chunks
        metadatas += metadatas_for_utterance_chunks
    
    return text_chunks, metadatas

def create_and_save_vector_embeddings(text_chunks: List[str], metadatas: List[str]):
    from pymongo.mongo_client import MongoClient
    from pymongo.server_api import ServerApi, ServerApiVersion
    from langchain.embeddings import OpenAIEmbeddings
    from langchain.vectorstores import MongoDBAtlasVectorSearch

    uri = os.environ['MONGODB_ATLAS_CLUSTER_URI']
    client = MongoClient(uri, server_api=ServerApi(ServerApiVersion.V1))

    db_name = "pod_search"
    collection_name = "podcast_episode_embeddings"
    collection = client[db_name][collection_name]
    index_name = "episode_embeddings"

    vector_store = MongoDBAtlasVectorSearch(
        collection,
        embedding=OpenAIEmbeddings(disallowed_special=()),
        index_name=index_name
    )

    vector_store.add_texts(text_chunks, metadatas)

# Can be done in parallel
def process_episode(podcast_episode: PodcastEpisode):
    audio_url = podcast_episode.audio_url
    # Add one for the podcast host
    num_speakers = len(get_names_in_text(podcast_episode.title)) + 1

    # If the podcast does not provide timestamps for the different "chapters" of the episode, have AssemblyAI generate them
    auto_chapters = True if podcast_episode.timestamps is None or len(podcast_episode.timestamps) == 0 else False
    # transcript = generate_transcript(audio_url, num_speakers, auto_chapters)
    transcript = get_generated_transcript('6na40xqpvm-0ce9-4f3b-82af-9f039117de14')

    document = create_episode_document(podcast_episode, transcript)
    # with open('episode_document.json', 'w') as file:
    #     json.dump(document, file, indent=4)

    chunks, metadatas = prep_episode_document_for_vector_embedding(document)

    create_and_save_vector_embeddings(chunks, metadatas)

    save_episode_document(document)

# Main
import feedparser

feed = feedparser.parse('https://feeds.megaphone.fm/hubermanlab')

podcast_episodes = []

# for entry in feed.entries[:5]:
#     podcast_episodes.append({
#         'original_guid': entry.id if "id" in entry else None,
#         'title': entry.title,
#         'link': entry.link,
#         'publish_date': entry.published,
#         'description': entry.description,
#         'timestamps': extract_episode_timestamps_and_titles(entry.description),
#         'mp3_url': entry.enclosures[0].href
#     })

search_string = "Mark Zuckerberg & Dr. Priscilla Chan"
entry = next((entry for entry in feed.entries if search_string in entry.title), None)

podcast_episode = PodcastEpisode(
    original_guid=entry.id if "id" in entry else None,
    podcast_name="Huberman Lab",
    podcast_host="Dr. Andrew Huberman",
    title=entry.title,
    link=entry.link,
    publish_date=entry.published,
    description=entry.description,
    timestamps=extract_episode_timestamps_and_titles(entry.description),
    audio_url=entry.enclosures[0].href
)

podcast_episodes.append(podcast_episode)

for podcast_episode in podcast_episodes:
   process_episode(podcast_episode)
